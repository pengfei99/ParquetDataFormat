{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. S3 select api introduction\n",
    "When we use frameworks such as Spark, or Arrow to retrieve objects from s3. They always retrieve the whole entities of the objects. For example, if spark read a paruqet file of 10 GiB in s3, a total 10 GiB of data will be transfered from s3 to the spark cluster. Even though spark may just require some of the columns and rows to do the calculation. As a result, we retrived many useless data that increase the I/O of the operation.\n",
    "\n",
    "To avoid this, the S3 Select API allows us to retrieve a subset of data by using simple SQL expressions. The data filtering happens on the s3 server. And only the data needed by the application will be retrieved. This can improve drasticly the operation performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, the S3 select api is designed for filtering columns and rows only. It's not designed for handling complex analytical queries and return results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Limitation of S3 Select\n",
    "- It supports a maximum of 256 KB length of an SQL expression.\n",
    "- It supports a maximum of 1 MB length of a record in the input or result.\n",
    "- Few SQL clauses that are supported are SELECT, FROM, WHERE, LIMIT, etc.\n",
    "- It is not useful for complex analytical queries and joins.\n",
    "- Currently, only three object formats, namely CSV, JSON, or Apache Parquet are supported by S3 Select queries.\n",
    "- At a time, the select query can execute on a single file (object).\n",
    "- It runs queries on a single object at a time in the S3 bucket.\n",
    "- Supported CompressionType: NONE, GZIP, BZIP2. Default Value: NONE.\n",
    "\n",
    "\n",
    "The first four limitation are normal, because S3 select is not designed for handling complex d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_id=os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "secret=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "session_token=os.getenv(\"AWS_SESSION_TOKEN\")\n",
    "endpoint=os.getenv(\"AWS_S3_ENDPOINT\")\n",
    "\n",
    "# print(f\"key id: {key_id}\")\n",
    "# print(f\"key secret: {secret}\")\n",
    "# print(f\"session token: {session_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing buckets:\n",
      "  donnees-insee\n",
      "  pengfei\n",
      "  projet-relevanc\n",
      "  projet-spark-lab\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url=f'https://{endpoint}',\n",
    "    aws_access_key_id=key_id,\n",
    "    aws_secret_access_key=secret,\n",
    "    aws_session_token=session_token\n",
    ")\n",
    "\n",
    "response = s3_client.list_buckets()\n",
    "\n",
    "# Output the bucket names\n",
    "print('Existing buckets:')\n",
    "for bucket in response['Buckets']:\n",
    "    print(f'  {bucket[\"Name\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_csv(bucket:str,path:str,query:str):\n",
    "    response = s3_client.select_object_content(\n",
    "               Bucket=bucket,\n",
    "               Key=path,\n",
    "               ExpressionType='SQL',\n",
    "               Expression=query,\n",
    "               InputSerialization = {'CSV': {\"FileHeaderInfo\": \"Use\"}, 'CompressionType': 'NONE'},\n",
    "               OutputSerialization = {'CSV': {}},)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv with s3 select.\n",
    "bucket=\"pengefi\"\n",
    "path=\"diffusion/data_format/netflix.csv\"\n",
    "q1=\"SELECT * FROM s3object s where s.\\\"rating\\\" = '5' limit 5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "822109,5,2005-05-13\n",
      "2207774,5,2005-06-06\n",
      "372233,5,2005-11-23\n",
      "814701,5,2005-09-29\n",
      "662870,5,2005-08-24\n",
      "\n",
      "Stats details bytesScanned: \n",
      "4194304\n",
      "Stats details bytesProcessed: \n",
      "4194304\n",
      "Stats details bytesReturned: \n",
      "101\n"
     ]
    }
   ],
   "source": [
    "resp1=\n",
    "\n",
    "for event in resp1['Payload']:\n",
    "    if 'Records' in event:\n",
    "        records = event['Records']['Payload'].decode('utf-8')\n",
    "        print(records)\n",
    "    elif 'Stats' in event:\n",
    "        statsDetails = event['Stats']['Details']\n",
    "        print(\"Stats details bytesScanned: \")\n",
    "        print(statsDetails['BytesScanned'])\n",
    "        print(\"Stats details bytesProcessed: \")\n",
    "        print(statsDetails['BytesProcessed'])\n",
    "        print(\"Stats details bytesReturned: \")\n",
    "        print(statsDetails['BytesReturned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (InternalError) when calling the SelectObjectContent operation (reached max retries: 4): We encountered an internal error, please try again.: cause(parquet format parsing not enabled on server)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d18a9c9a193c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mExpression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SELECT * FROM s3object limit 5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mInputSerialization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'Parquet'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CompressionType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'NONE'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mOutputSerialization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'CSV'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (InternalError) when calling the SelectObjectContent operation (reached max retries: 4): We encountered an internal error, please try again.: cause(parquet format parsing not enabled on server)"
     ]
    }
   ],
   "source": [
    "# read parquet with s3 select.\n",
    "data_path=\"diffusion/data_format/sf_fire/parquet/arrow_sf_fire_none/f402f99cb6d9459696314909b6f6e0a3.parquet\"\n",
    "\n",
    "resp = s3_client.select_object_content(\n",
    "    Bucket='pengfei',\n",
    "    Key=data_path,\n",
    "    ExpressionType='SQL',\n",
    "    Expression=\"SELECT * FROM s3object limit 5\",\n",
    "    InputSerialization = {'Parquet': {}, 'CompressionType': 'NONE'},\n",
    "    OutputSerialization = {'CSV': {}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
